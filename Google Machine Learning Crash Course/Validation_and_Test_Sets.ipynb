{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation_and_Test_Sets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walidsi/Data-Science/blob/master/Google%20Machine%20Learning%20Crash%20Course/Validation_and_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3CKqFUqL2-",
        "colab_type": "text"
      },
      "source": [
        "# Validation Sets and Test Sets\n",
        "\n",
        "The previous Colab exercises evaluated the trained model against the training set, which does not provide a strong signal about the quality of your model. In this Colab, you'll experiment with validation sets and test sets.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3spZH_kNkWWX",
        "colab_type": "text"
      },
      "source": [
        "## Learning objectives\n",
        "\n",
        "After doing this Colab, you'll know how to do the following:\n",
        "\n",
        "  * Split a [training set](https://developers.google.com/machine-learning/glossary/#training_set) into a smaller training set and a [validation set](https://developers.google.com/machine-learning/glossary/#validation_set).\n",
        "  * Analyze deltas between training set and validation set results.\n",
        "  * Test the trained model with a [test set](https://developers.google.com/machine-learning/glossary/#test_set) to determine whether your trained model is [overfitting](https://developers.google.com/machine-learning/glossary/#overfitting).\n",
        "  * Detect and fix a common training problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV82DJO3kWpk",
        "colab_type": "text"
      },
      "source": [
        "## The dataset\n",
        "\n",
        "As in the previous exercise, this exercise uses the [California Housing dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) to predict the `median_house_value` at the city block level.  Like many \"famous\" datasets, the California Housing Dataset actually consists of two separate datasets, each living in separate .csv files:\n",
        "\n",
        "* The training set is in `california_housing_train.csv`.\n",
        "* The test set is in `california_housing_test.csv`.\n",
        "\n",
        "You'll create the validation set by dividing the downloaded training set into two parts:\n",
        "\n",
        "* a smaller training set  \n",
        "* a validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u84mXopntPFZ",
        "colab_type": "text"
      },
      "source": [
        "## Use the right version of TensorFlow\n",
        "\n",
        "The following hidden code cell ensures that the Colab will run on TensorFlow 2.X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhNIdUatOU6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8gm6BpqRRuh",
        "colab_type": "text"
      },
      "source": [
        "## Import relevant modules\n",
        "\n",
        "As before, this first code cell imports the necessary modules and sets a few display options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8GgUovHbG0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjvrrClQeAJu",
        "colab_type": "text"
      },
      "source": [
        "## Load the datasets from the internet\n",
        "\n",
        "The following code cell loads the separate .csv files and creates the following two pandas DataFrames:\n",
        "\n",
        "* `train_df`, which contains the training set.\n",
        "* `test_df`, which contains the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUnTc_wfd_o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_KBdj2M_yjM",
        "colab_type": "text"
      },
      "source": [
        "## Scale the label values\n",
        "\n",
        "The following code cell scales the `median_house_value`. \n",
        "See the previous Colab exercise for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hc7QQhaAFXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale_factor = 1000.0\n",
        "\n",
        "# Scale the training set's label.\n",
        "train_df[\"median_house_value\"] /= scale_factor \n",
        "\n",
        "# Scale the test set's label\n",
        "test_df[\"median_house_value\"] /= scale_factor"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhessIIV8VPc",
        "colab_type": "text"
      },
      "source": [
        "## Load the functions that build and train a model\n",
        "\n",
        "The following code cell defines two functions:\n",
        "\n",
        "  * `build_model`, which defines the model's topography.\n",
        "  * `train_model`, which will ultimately train the model, outputting not only the loss value for the training set but also the loss value for the validation set. \n",
        "\n",
        "Since you don't need to understand model building code right now, we've hidden this code cell. As always, you must run hidden code cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvonhK857msj",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "168be788-3b9e-4f90-d56a-9df8527f0ffe"
      },
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model               \n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, my_epochs, \n",
        "                my_batch_size=None, my_validation_split=0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=my_batch_size,\n",
        "                      epochs=my_epochs,\n",
        "                      validation_split=my_validation_split)\n",
        "\n",
        "  # Gather the model's trained weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the \n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Isolate the root mean squared error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the build_model and train_model functions.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the build_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gRu4Ri0D8tH",
        "colab_type": "text"
      },
      "source": [
        "## Define plotting functions\n",
        "\n",
        "The `plot_the_loss_curve` function plots loss vs. epochs for both the training set and the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA7hsqPZDvVM",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c307e1e4-190c-464c-90d4-df678657d1c7"
      },
      "source": [
        "#@title Define the plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_lists)\n",
        "  lowest_loss = min(merged_mae_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "   \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jipBqEQXlsN8",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Experiment with the validation split\n",
        "\n",
        "In the following code cell, you'll see a variable named `validation_split`, which we've initialized at 0.2.  The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a `validation_split` of 0.2 means that:\n",
        "\n",
        "* 17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
        "* 17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "\n",
        "* The training set.\n",
        "* And the validation set.\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are **not** almost identical. Hmm, that's odd.  \n",
        "\n",
        "Experiment with two or three different values of `validation_split`.  Do different values of `validation_split` fix the problem? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knP23Taoa00a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc94b5bb-1271-4325-fa63-d3b5a3de4687"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.6\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Invoke the functions to build and train the model.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 39813.8711 - root_mean_squared_error: 199.5341 - val_loss: 46599.4375 - val_root_mean_squared_error: 215.8690\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 30253.9180 - root_mean_squared_error: 173.9365 - val_loss: 36457.3242 - val_root_mean_squared_error: 190.9380\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 22350.3301 - root_mean_squared_error: 149.5003 - val_loss: 27862.6230 - val_root_mean_squared_error: 166.9210\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 15917.0391 - root_mean_squared_error: 126.1628 - val_loss: 20867.3301 - val_root_mean_squared_error: 144.4553\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 11048.5186 - root_mean_squared_error: 105.1119 - val_loss: 15516.4160 - val_root_mean_squared_error: 124.5649\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7604.5396 - root_mean_squared_error: 87.2040 - val_loss: 11705.3086 - val_root_mean_squared_error: 108.1911\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5651.0024 - root_mean_squared_error: 75.1731 - val_loss: 9472.6318 - val_root_mean_squared_error: 97.3274\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4933.2344 - root_mean_squared_error: 70.2370 - val_loss: 8711.5010 - val_root_mean_squared_error: 93.3354\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4871.5381 - root_mean_squared_error: 69.7964 - val_loss: 8646.0215 - val_root_mean_squared_error: 92.9840\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4866.4707 - root_mean_squared_error: 69.7601 - val_loss: 8704.4287 - val_root_mean_squared_error: 93.2975\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4866.5044 - root_mean_squared_error: 69.7603 - val_loss: 8670.3838 - val_root_mean_squared_error: 93.1149\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4864.2607 - root_mean_squared_error: 69.7443 - val_loss: 8648.7256 - val_root_mean_squared_error: 92.9985\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4862.5845 - root_mean_squared_error: 69.7322 - val_loss: 8641.7783 - val_root_mean_squared_error: 92.9612\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4860.0850 - root_mean_squared_error: 69.7143 - val_loss: 8687.5420 - val_root_mean_squared_error: 93.2070\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4858.3467 - root_mean_squared_error: 69.7018 - val_loss: 8623.6953 - val_root_mean_squared_error: 92.8639\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4859.3276 - root_mean_squared_error: 69.7089 - val_loss: 8648.8652 - val_root_mean_squared_error: 92.9993\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4858.7749 - root_mean_squared_error: 69.7049 - val_loss: 8669.7119 - val_root_mean_squared_error: 93.1113\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4857.7529 - root_mean_squared_error: 69.6976 - val_loss: 8646.5039 - val_root_mean_squared_error: 92.9866\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4858.1543 - root_mean_squared_error: 69.7005 - val_loss: 8663.1982 - val_root_mean_squared_error: 93.0763\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4857.2080 - root_mean_squared_error: 69.6937 - val_loss: 8711.7588 - val_root_mean_squared_error: 93.3368\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4856.9648 - root_mean_squared_error: 69.6919 - val_loss: 8708.4209 - val_root_mean_squared_error: 93.3189\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4857.5254 - root_mean_squared_error: 69.6960 - val_loss: 8683.1768 - val_root_mean_squared_error: 93.1836\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 4856.7407 - root_mean_squared_error: 69.6903 - val_loss: 8703.8018 - val_root_mean_squared_error: 93.2942\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4856.8398 - root_mean_squared_error: 69.6910 - val_loss: 8720.8936 - val_root_mean_squared_error: 93.3857\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4856.6504 - root_mean_squared_error: 69.6897 - val_loss: 8681.7461 - val_root_mean_squared_error: 93.1759\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4856.7798 - root_mean_squared_error: 69.6906 - val_loss: 8687.6787 - val_root_mean_squared_error: 93.2077\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4856.5542 - root_mean_squared_error: 69.6890 - val_loss: 8650.3965 - val_root_mean_squared_error: 93.0075\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4855.7422 - root_mean_squared_error: 69.6832 - val_loss: 8625.9248 - val_root_mean_squared_error: 92.8759\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4856.6289 - root_mean_squared_error: 69.6895 - val_loss: 8658.7109 - val_root_mean_squared_error: 93.0522\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4856.4292 - root_mean_squared_error: 69.6881 - val_loss: 8648.1709 - val_root_mean_squared_error: 92.9955\n",
            "121.2548599243164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKa11JK4Pm3f",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Determine **why** the loss curves differ\n",
        "\n",
        "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning. \n",
        "\n",
        "Your task is to determine **why** the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of [pandas code](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=validation-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en) in the following code cell.  Here are a couple of hints:\n",
        "\n",
        "  * The previous code cell split the original training set into:\n",
        "    * a reduced training set (the original training set - the validation set)\n",
        "    * the validation set \n",
        "  * By default, the pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method outputs the *first* 5 rows of the DataFrame. To see more of the training set, specify the `n` argument to `head` and assign a large positive integer to `n`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJQcAZkwJt_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "c22a8ea7-9651-4728-96b6-460945b3e3e0"
      },
      "source": [
        "# Write some code in this code cell.\n",
        "train_df.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-115.3</td>\n",
              "      <td>32.8</td>\n",
              "      <td>34.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1602.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>71.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1276.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>867.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>80.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>623.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>68.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1458.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>74.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    longitude  latitude  ...  median_income  median_house_value\n",
              "0      -114.3      34.2  ...            1.5                66.9\n",
              "1      -114.5      34.4  ...            1.8                80.1\n",
              "2      -114.6      33.7  ...            1.7                85.7\n",
              "3      -114.6      33.6  ...            3.2                73.4\n",
              "4      -114.6      33.6  ...            1.9                65.5\n",
              "..        ...       ...  ...            ...                 ...\n",
              "25     -115.3      32.8  ...            3.7               100.0\n",
              "26     -115.4      32.8  ...            3.6                71.1\n",
              "27     -115.4      32.8  ...            1.9                80.9\n",
              "28     -115.4      32.8  ...            1.8                68.6\n",
              "29     -115.4      32.8  ...            2.4                74.3\n",
              "\n",
              "[30 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnNvkFwwK8WY",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "301f0da8-9b3c-4ff9-e2c7-e89b5ec4c919"
      },
      "source": [
        "#@title Double-click for a possible solution to Task 2.\n",
        "\n",
        "# Examine examples 0 through 4 and examples 25 through 29\n",
        "# of the training set\n",
        "train_df.head(n=1000)\n",
        "\n",
        "# The original training set is sorted by longitude. \n",
        "# Apparently, longitude influences the relationship of\n",
        "# total_rooms to median_house_value."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.2</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     longitude  latitude  ...  median_income  median_house_value\n",
              "0       -114.3      34.2  ...            1.5                66.9\n",
              "1       -114.5      34.4  ...            1.8                80.1\n",
              "2       -114.6      33.7  ...            1.7                85.7\n",
              "3       -114.6      33.6  ...            3.2                73.4\n",
              "4       -114.6      33.6  ...            1.9                65.5\n",
              "..         ...       ...  ...            ...                 ...\n",
              "995     -117.1      32.5  ...            4.0               144.4\n",
              "996     -117.1      34.6  ...            3.2               112.8\n",
              "997     -117.1      34.2  ...            4.5               108.4\n",
              "998     -117.1      34.0  ...            2.5                96.0\n",
              "999     -117.1      33.6  ...            4.4               307.6\n",
              "\n",
              "[1000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw4xI1ZEckI8",
        "colab_type": "text"
      },
      "source": [
        "## Task 3. Fix the problem\n",
        "\n",
        "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and validation set. To do so, take the following steps:\n",
        "\n",
        "1. Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (in the code cell associated with Task 1):\n",
        "\n",
        "```\n",
        "  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
        "```                                    \n",
        "\n",
        "2. Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (in the code call associated with Task 1) so that the call becomes as follows:\n",
        "\n",
        "```\n",
        "  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                      my_label, epochs, batch_size, \n",
        "                                      validation_split)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncODhpv0h-LG",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21a05e98-3181-4b14-e632-d1d44984c618"
      },
      "source": [
        "#@title Double-click to view the complete implementation.\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.5\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Shuffle the examples.\n",
        "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n",
        "\n",
        "# Invoke the functions to build and train the model. Train on the shuffled\n",
        "# training set.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "85/85 [==============================] - 0s 3ms/step - loss: 49341.9531 - root_mean_squared_error: 222.1305 - val_loss: 40541.4648 - val_root_mean_squared_error: 201.3491\n",
            "Epoch 2/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 36077.2461 - root_mean_squared_error: 189.9401 - val_loss: 29085.4961 - val_root_mean_squared_error: 170.5447\n",
            "Epoch 3/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 25502.1973 - root_mean_squared_error: 159.6941 - val_loss: 20049.5234 - val_root_mean_squared_error: 141.5963\n",
            "Epoch 4/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 17338.3457 - root_mean_squared_error: 131.6752 - val_loss: 13394.9746 - val_root_mean_squared_error: 115.7367\n",
            "Epoch 5/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 11609.7266 - root_mean_squared_error: 107.7484 - val_loss: 9174.0527 - val_root_mean_squared_error: 95.7813\n",
            "Epoch 6/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 8304.0273 - root_mean_squared_error: 91.1264 - val_loss: 7237.8887 - val_root_mean_squared_error: 85.0758\n",
            "Epoch 7/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7118.2090 - root_mean_squared_error: 84.3695 - val_loss: 6990.6519 - val_root_mean_squared_error: 83.6101\n",
            "Epoch 8/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.4629 - root_mean_squared_error: 83.9015 - val_loss: 6991.8726 - val_root_mean_squared_error: 83.6174\n",
            "Epoch 9/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.5820 - root_mean_squared_error: 83.8963 - val_loss: 6994.5264 - val_root_mean_squared_error: 83.6333\n",
            "Epoch 10/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.4736 - root_mean_squared_error: 83.8956 - val_loss: 6992.9805 - val_root_mean_squared_error: 83.6240\n",
            "Epoch 11/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.0786 - root_mean_squared_error: 83.8992 - val_loss: 6990.5342 - val_root_mean_squared_error: 83.6094\n",
            "Epoch 12/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.9429 - root_mean_squared_error: 83.8924 - val_loss: 6991.7236 - val_root_mean_squared_error: 83.6165\n",
            "Epoch 13/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.1030 - root_mean_squared_error: 83.8934 - val_loss: 7004.4512 - val_root_mean_squared_error: 83.6926\n",
            "Epoch 14/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0508 - root_mean_squared_error: 83.8931 - val_loss: 6990.7295 - val_root_mean_squared_error: 83.6106\n",
            "Epoch 15/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.5649 - root_mean_squared_error: 83.8962 - val_loss: 6993.4351 - val_root_mean_squared_error: 83.6268\n",
            "Epoch 16/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.6104 - root_mean_squared_error: 83.8964 - val_loss: 6988.9155 - val_root_mean_squared_error: 83.5997\n",
            "Epoch 17/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.7275 - root_mean_squared_error: 83.8971 - val_loss: 6989.4731 - val_root_mean_squared_error: 83.6031\n",
            "Epoch 18/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.9546 - root_mean_squared_error: 83.8985 - val_loss: 6992.8179 - val_root_mean_squared_error: 83.6231\n",
            "Epoch 19/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.4053 - root_mean_squared_error: 83.8952 - val_loss: 7000.4175 - val_root_mean_squared_error: 83.6685\n",
            "Epoch 20/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.1396 - root_mean_squared_error: 83.8996 - val_loss: 6998.6694 - val_root_mean_squared_error: 83.6581\n",
            "Epoch 21/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.2490 - root_mean_squared_error: 83.8943 - val_loss: 6994.2510 - val_root_mean_squared_error: 83.6316\n",
            "Epoch 22/70\n",
            "85/85 [==============================] - 0s 3ms/step - loss: 7039.2339 - root_mean_squared_error: 83.9001 - val_loss: 6991.3843 - val_root_mean_squared_error: 83.6145\n",
            "Epoch 23/70\n",
            "85/85 [==============================] - 0s 3ms/step - loss: 7038.0649 - root_mean_squared_error: 83.8932 - val_loss: 6996.3862 - val_root_mean_squared_error: 83.6444\n",
            "Epoch 24/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0146 - root_mean_squared_error: 83.8929 - val_loss: 7000.0869 - val_root_mean_squared_error: 83.6665\n",
            "Epoch 25/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.5283 - root_mean_squared_error: 83.8959 - val_loss: 6996.5659 - val_root_mean_squared_error: 83.6455\n",
            "Epoch 26/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.3882 - root_mean_squared_error: 83.9011 - val_loss: 6992.2979 - val_root_mean_squared_error: 83.6200\n",
            "Epoch 27/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.7710 - root_mean_squared_error: 83.8974 - val_loss: 6995.6689 - val_root_mean_squared_error: 83.6401\n",
            "Epoch 28/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.4932 - root_mean_squared_error: 83.8957 - val_loss: 6990.3599 - val_root_mean_squared_error: 83.6084\n",
            "Epoch 29/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.7383 - root_mean_squared_error: 83.8972 - val_loss: 6987.7925 - val_root_mean_squared_error: 83.5930\n",
            "Epoch 30/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.3608 - root_mean_squared_error: 83.9009 - val_loss: 6991.8408 - val_root_mean_squared_error: 83.6172\n",
            "Epoch 31/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.3242 - root_mean_squared_error: 83.8947 - val_loss: 6998.8657 - val_root_mean_squared_error: 83.6592\n",
            "Epoch 32/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.2378 - root_mean_squared_error: 83.8942 - val_loss: 7001.2480 - val_root_mean_squared_error: 83.6735\n",
            "Epoch 33/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.9424 - root_mean_squared_error: 83.8924 - val_loss: 6993.4429 - val_root_mean_squared_error: 83.6268\n",
            "Epoch 34/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.5562 - root_mean_squared_error: 83.8901 - val_loss: 7005.0854 - val_root_mean_squared_error: 83.6964\n",
            "Epoch 35/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.4219 - root_mean_squared_error: 83.8953 - val_loss: 6989.6558 - val_root_mean_squared_error: 83.6042\n",
            "Epoch 36/70\n",
            "85/85 [==============================] - 0s 3ms/step - loss: 7038.4458 - root_mean_squared_error: 83.8954 - val_loss: 6988.5415 - val_root_mean_squared_error: 83.5975\n",
            "Epoch 37/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.4688 - root_mean_squared_error: 83.8956 - val_loss: 6994.4702 - val_root_mean_squared_error: 83.6329\n",
            "Epoch 38/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.2070 - root_mean_squared_error: 83.8940 - val_loss: 6998.6782 - val_root_mean_squared_error: 83.6581\n",
            "Epoch 39/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.5781 - root_mean_squared_error: 83.8903 - val_loss: 6992.2188 - val_root_mean_squared_error: 83.6195\n",
            "Epoch 40/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.7817 - root_mean_squared_error: 83.8974 - val_loss: 6994.8027 - val_root_mean_squared_error: 83.6349\n",
            "Epoch 41/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.3105 - root_mean_squared_error: 83.8946 - val_loss: 7001.3652 - val_root_mean_squared_error: 83.6742\n",
            "Epoch 42/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.1689 - root_mean_squared_error: 83.8997 - val_loss: 6997.4121 - val_root_mean_squared_error: 83.6505\n",
            "Epoch 43/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7036.9517 - root_mean_squared_error: 83.8865 - val_loss: 6999.8164 - val_root_mean_squared_error: 83.6649\n",
            "Epoch 44/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.6782 - root_mean_squared_error: 83.8909 - val_loss: 6987.7363 - val_root_mean_squared_error: 83.5927\n",
            "Epoch 45/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0601 - root_mean_squared_error: 83.8932 - val_loss: 7004.4780 - val_root_mean_squared_error: 83.6928\n",
            "Epoch 46/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.0107 - root_mean_squared_error: 83.8988 - val_loss: 6988.8818 - val_root_mean_squared_error: 83.5995\n",
            "Epoch 47/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.5176 - root_mean_squared_error: 83.8959 - val_loss: 6989.2754 - val_root_mean_squared_error: 83.6019\n",
            "Epoch 48/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.5898 - root_mean_squared_error: 83.9023 - val_loss: 6987.8306 - val_root_mean_squared_error: 83.5932\n",
            "Epoch 49/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.4023 - root_mean_squared_error: 83.9011 - val_loss: 6990.9175 - val_root_mean_squared_error: 83.6117\n",
            "Epoch 50/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.5503 - root_mean_squared_error: 83.8961 - val_loss: 6990.3496 - val_root_mean_squared_error: 83.6083\n",
            "Epoch 51/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.2002 - root_mean_squared_error: 83.8940 - val_loss: 6996.0591 - val_root_mean_squared_error: 83.6424\n",
            "Epoch 52/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7036.9399 - root_mean_squared_error: 83.8865 - val_loss: 6989.2197 - val_root_mean_squared_error: 83.6016\n",
            "Epoch 53/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.8096 - root_mean_squared_error: 83.8976 - val_loss: 6990.0107 - val_root_mean_squared_error: 83.6063\n",
            "Epoch 54/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0107 - root_mean_squared_error: 83.8929 - val_loss: 7000.9604 - val_root_mean_squared_error: 83.6717\n",
            "Epoch 55/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.3867 - root_mean_squared_error: 83.8951 - val_loss: 6997.1265 - val_root_mean_squared_error: 83.6488\n",
            "Epoch 56/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0410 - root_mean_squared_error: 83.8930 - val_loss: 7000.5771 - val_root_mean_squared_error: 83.6694\n",
            "Epoch 57/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.2158 - root_mean_squared_error: 83.9000 - val_loss: 6996.1382 - val_root_mean_squared_error: 83.6429\n",
            "Epoch 58/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0132 - root_mean_squared_error: 83.8929 - val_loss: 6989.2646 - val_root_mean_squared_error: 83.6018\n",
            "Epoch 59/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.2241 - root_mean_squared_error: 83.8941 - val_loss: 6997.9888 - val_root_mean_squared_error: 83.6540\n",
            "Epoch 60/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7037.9043 - root_mean_squared_error: 83.8922 - val_loss: 6990.3540 - val_root_mean_squared_error: 83.6083\n",
            "Epoch 61/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7036.8125 - root_mean_squared_error: 83.8857 - val_loss: 6985.3823 - val_root_mean_squared_error: 83.5786\n",
            "Epoch 62/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.6523 - root_mean_squared_error: 83.9026 - val_loss: 6991.0327 - val_root_mean_squared_error: 83.6124\n",
            "Epoch 63/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.1968 - root_mean_squared_error: 83.8940 - val_loss: 6990.9941 - val_root_mean_squared_error: 83.6122\n",
            "Epoch 64/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.1313 - root_mean_squared_error: 83.8936 - val_loss: 6987.8975 - val_root_mean_squared_error: 83.5937\n",
            "Epoch 65/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.9644 - root_mean_squared_error: 83.9045 - val_loss: 6990.2153 - val_root_mean_squared_error: 83.6075\n",
            "Epoch 66/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.0840 - root_mean_squared_error: 83.8933 - val_loss: 6997.4326 - val_root_mean_squared_error: 83.6507\n",
            "Epoch 67/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7036.3442 - root_mean_squared_error: 83.8829 - val_loss: 7016.3218 - val_root_mean_squared_error: 83.7635\n",
            "Epoch 68/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7038.3052 - root_mean_squared_error: 83.8946 - val_loss: 6993.9404 - val_root_mean_squared_error: 83.6298\n",
            "Epoch 69/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.4146 - root_mean_squared_error: 83.9012 - val_loss: 6998.6719 - val_root_mean_squared_error: 83.6581\n",
            "Epoch 70/70\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7039.1030 - root_mean_squared_error: 83.8994 - val_loss: 6991.2705 - val_root_mean_squared_error: 83.6138\n",
            "106.36151123046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKN239_miW8C",
        "colab_type": "text"
      },
      "source": [
        "Experiment with `validation_split` to answer the following questions:\n",
        "\n",
        "* With the training set shuffled, is the final loss for the training set closer to the final loss for the validation set?  \n",
        "* At what range of values of `validation_split` do the final loss values for the training set and validation set diverge meaningfully?  Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UAJ3Q86iz31",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Double-click for the answers to the questions\n",
        "\n",
        "# Yes, after shuffling the original training set, \n",
        "# the final loss for the training set and the \n",
        "# validation set become much closer.\n",
        "\n",
        "# If validation_split < 0.15,\n",
        "# the final loss values for the training set and\n",
        "# validation set diverge meaningfully.  Apparently,\n",
        "# the validation set no longer contains enough examples. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PP-O8TOZOeo",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n",
        "\n",
        "The test set usually acts as the ultimate judge of a model's quality. The test set can serve as an impartial judge because its examples haven't been used in training the model. Run the following code cell to evaluate the model with the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd_Sw2cygOip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efcae454-6e67-480e-9a98-fdb2d35c13e4"
      },
      "source": [
        "x_test = test_df[my_feature]\n",
        "y_test = test_df[my_label]\n",
        "\n",
        "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 917us/step - loss: 7008.4658 - root_mean_squared_error: 83.7166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoyQKvsjmV_A",
        "colab_type": "text"
      },
      "source": [
        "Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
        "\n",
        "* training set: look for `root_mean_squared_error` in the final training epoch.\n",
        "* validation set: look for `val_root_mean_squared_error` in the final training epoch.\n",
        "* test set: run the preceding code cell and examine the `root_mean_squred_error`.\n",
        "\n",
        "Ideally, the root mean squared error of all three sets should be similar. Are they?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXtp-aVdIgJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Double-click for an answer\n",
        "\n",
        "# In our experiments, yes, the rmse values \n",
        "# were similar enough. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}