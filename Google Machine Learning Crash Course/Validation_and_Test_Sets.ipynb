{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation_and_Test_Sets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walidsi/Data-Science/blob/master/Google%20Machine%20Learning%20Crash%20Course/Validation_and_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3CKqFUqL2-",
        "colab_type": "text"
      },
      "source": [
        "# Validation Sets and Test Sets\n",
        "\n",
        "The previous Colab exercises evaluated the trained model against the training set, which does not provide a strong signal about the quality of your model. In this Colab, you'll experiment with validation sets and test sets.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3spZH_kNkWWX",
        "colab_type": "text"
      },
      "source": [
        "## Learning objectives\n",
        "\n",
        "After doing this Colab, you'll know how to do the following:\n",
        "\n",
        "  * Split a [training set](https://developers.google.com/machine-learning/glossary/#training_set) into a smaller training set and a [validation set](https://developers.google.com/machine-learning/glossary/#validation_set).\n",
        "  * Analyze deltas between training set and validation set results.\n",
        "  * Test the trained model with a [test set](https://developers.google.com/machine-learning/glossary/#test_set) to determine whether your trained model is [overfitting](https://developers.google.com/machine-learning/glossary/#overfitting).\n",
        "  * Detect and fix a common training problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV82DJO3kWpk",
        "colab_type": "text"
      },
      "source": [
        "## The dataset\n",
        "\n",
        "As in the previous exercise, this exercise uses the [California Housing dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) to predict the `median_house_value` at the city block level.  Like many \"famous\" datasets, the California Housing Dataset actually consists of two separate datasets, each living in separate .csv files:\n",
        "\n",
        "* The training set is in `california_housing_train.csv`.\n",
        "* The test set is in `california_housing_test.csv`.\n",
        "\n",
        "You'll create the validation set by dividing the downloaded training set into two parts:\n",
        "\n",
        "* a smaller training set  \n",
        "* a validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u84mXopntPFZ",
        "colab_type": "text"
      },
      "source": [
        "## Use the right version of TensorFlow\n",
        "\n",
        "The following hidden code cell ensures that the Colab will run on TensorFlow 2.X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhNIdUatOU6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8gm6BpqRRuh",
        "colab_type": "text"
      },
      "source": [
        "## Import relevant modules\n",
        "\n",
        "As before, this first code cell imports the necessary modules and sets a few display options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8GgUovHbG0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjvrrClQeAJu",
        "colab_type": "text"
      },
      "source": [
        "## Load the datasets from the internet\n",
        "\n",
        "The following code cell loads the separate .csv files and creates the following two pandas DataFrames:\n",
        "\n",
        "* `train_df`, which contains the training set.\n",
        "* `test_df`, which contains the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUnTc_wfd_o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_KBdj2M_yjM",
        "colab_type": "text"
      },
      "source": [
        "## Scale the label values\n",
        "\n",
        "The following code cell scales the `median_house_value`. \n",
        "See the previous Colab exercise for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hc7QQhaAFXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale_factor = 1000.0\n",
        "\n",
        "# Scale the training set's label.\n",
        "train_df[\"median_house_value\"] /= scale_factor \n",
        "\n",
        "# Scale the test set's label\n",
        "test_df[\"median_house_value\"] /= scale_factor"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhessIIV8VPc",
        "colab_type": "text"
      },
      "source": [
        "## Load the functions that build and train a model\n",
        "\n",
        "The following code cell defines two functions:\n",
        "\n",
        "  * `build_model`, which defines the model's topography.\n",
        "  * `train_model`, which will ultimately train the model, outputting not only the loss value for the training set but also the loss value for the validation set. \n",
        "\n",
        "Since you don't need to understand model building code right now, we've hidden this code cell. As always, you must run hidden code cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvonhK857msj",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a9979ee-cd88-4427-b554-63d0cc53ef33"
      },
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model               \n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, my_epochs, \n",
        "                my_batch_size=None, my_validation_split=0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=my_batch_size,\n",
        "                      epochs=my_epochs,\n",
        "                      validation_split=my_validation_split)\n",
        "\n",
        "  # Gather the model's trained weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the \n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Isolate the root mean squared error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the build_model and train_model functions.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the build_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gRu4Ri0D8tH",
        "colab_type": "text"
      },
      "source": [
        "## Define plotting functions\n",
        "\n",
        "The `plot_the_loss_curve` function plots loss vs. epochs for both the training set and the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA7hsqPZDvVM",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "209d1e96-d03c-42a9-b9e5-2ec27fe9b090"
      },
      "source": [
        "#@title Define the plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_lists)\n",
        "  lowest_loss = min(merged_mae_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "   \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jipBqEQXlsN8",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Experiment with the validation split\n",
        "\n",
        "In the following code cell, you'll see a variable named `validation_split`, which we've initialized at 0.2.  The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a `validation_split` of 0.2 means that:\n",
        "\n",
        "* 17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
        "* 17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "\n",
        "* The training set.\n",
        "* And the validation set.\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are **not** almost identical. Hmm, that's odd.  \n",
        "\n",
        "Experiment with two or three different values of `validation_split`.  Do different values of `validation_split` fix the problem? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knP23Taoa00a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91feb2c8-b0d0-48a5-da68-4df13f7642c9"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.5\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Invoke the functions to build and train the model.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 50963.2305 - root_mean_squared_error: 225.7504 - val_loss: 40769.2422 - val_root_mean_squared_error: 201.9139\n",
            "Epoch 2/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 37502.7539 - root_mean_squared_error: 193.6563 - val_loss: 29309.1426 - val_root_mean_squared_error: 171.1991\n",
            "Epoch 3/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 26586.5195 - root_mean_squared_error: 163.0537 - val_loss: 20192.1289 - val_root_mean_squared_error: 142.0990\n",
            "Epoch 4/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 18106.6035 - root_mean_squared_error: 134.5608 - val_loss: 13539.1289 - val_root_mean_squared_error: 116.3578\n",
            "Epoch 5/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 12095.8262 - root_mean_squared_error: 109.9810 - val_loss: 9303.9092 - val_root_mean_squared_error: 96.4568\n",
            "Epoch 6/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 8414.0615 - root_mean_squared_error: 91.7282 - val_loss: 7348.3008 - val_root_mean_squared_error: 85.7222\n",
            "Epoch 7/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 7021.0698 - root_mean_squared_error: 83.7918 - val_loss: 7163.8193 - val_root_mean_squared_error: 84.6394\n",
            "Epoch 8/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6847.3872 - root_mean_squared_error: 82.7489 - val_loss: 7237.1479 - val_root_mean_squared_error: 85.0714\n",
            "Epoch 9/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6837.4106 - root_mean_squared_error: 82.6886 - val_loss: 7224.4111 - val_root_mean_squared_error: 84.9965\n",
            "Epoch 10/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6827.6934 - root_mean_squared_error: 82.6299 - val_loss: 7271.6436 - val_root_mean_squared_error: 85.2739\n",
            "Epoch 11/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6822.9985 - root_mean_squared_error: 82.6014 - val_loss: 7270.5298 - val_root_mean_squared_error: 85.2674\n",
            "Epoch 12/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6816.4561 - root_mean_squared_error: 82.5618 - val_loss: 7273.5098 - val_root_mean_squared_error: 85.2849\n",
            "Epoch 13/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6812.1211 - root_mean_squared_error: 82.5356 - val_loss: 7282.6147 - val_root_mean_squared_error: 85.3382\n",
            "Epoch 14/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6807.3857 - root_mean_squared_error: 82.5069 - val_loss: 7273.7637 - val_root_mean_squared_error: 85.2864\n",
            "Epoch 15/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6805.5400 - root_mean_squared_error: 82.4957 - val_loss: 7314.5474 - val_root_mean_squared_error: 85.5251\n",
            "Epoch 16/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6802.9380 - root_mean_squared_error: 82.4799 - val_loss: 7317.7974 - val_root_mean_squared_error: 85.5441\n",
            "Epoch 17/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6800.9922 - root_mean_squared_error: 82.4681 - val_loss: 7316.1914 - val_root_mean_squared_error: 85.5347\n",
            "Epoch 18/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6801.0796 - root_mean_squared_error: 82.4687 - val_loss: 7327.9414 - val_root_mean_squared_error: 85.6034\n",
            "Epoch 19/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6799.3496 - root_mean_squared_error: 82.4582 - val_loss: 7324.5615 - val_root_mean_squared_error: 85.5836\n",
            "Epoch 20/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6798.9106 - root_mean_squared_error: 82.4555 - val_loss: 7330.5396 - val_root_mean_squared_error: 85.6186\n",
            "Epoch 21/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6798.8862 - root_mean_squared_error: 82.4554 - val_loss: 7336.3682 - val_root_mean_squared_error: 85.6526\n",
            "Epoch 22/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6797.2554 - root_mean_squared_error: 82.4455 - val_loss: 7336.8589 - val_root_mean_squared_error: 85.6555\n",
            "Epoch 23/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6797.6079 - root_mean_squared_error: 82.4476 - val_loss: 7351.6729 - val_root_mean_squared_error: 85.7419\n",
            "Epoch 24/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6796.7251 - root_mean_squared_error: 82.4423 - val_loss: 7364.5728 - val_root_mean_squared_error: 85.8171\n",
            "Epoch 25/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6795.4824 - root_mean_squared_error: 82.4347 - val_loss: 7362.8062 - val_root_mean_squared_error: 85.8068\n",
            "Epoch 26/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6795.4648 - root_mean_squared_error: 82.4346 - val_loss: 7369.5342 - val_root_mean_squared_error: 85.8460\n",
            "Epoch 27/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6796.0674 - root_mean_squared_error: 82.4383 - val_loss: 7365.0674 - val_root_mean_squared_error: 85.8200\n",
            "Epoch 28/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6795.1895 - root_mean_squared_error: 82.4329 - val_loss: 7376.3101 - val_root_mean_squared_error: 85.8854\n",
            "Epoch 29/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6795.1377 - root_mean_squared_error: 82.4326 - val_loss: 7355.4937 - val_root_mean_squared_error: 85.7642\n",
            "Epoch 30/30\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6795.6377 - root_mean_squared_error: 82.4357 - val_loss: 7386.0713 - val_root_mean_squared_error: 85.9423\n",
            "111.2236557006836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKa11JK4Pm3f",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Determine **why** the loss curves differ\n",
        "\n",
        "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning. \n",
        "\n",
        "Your task is to determine **why** the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of [pandas code](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=validation-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en) in the following code cell.  Here are a couple of hints:\n",
        "\n",
        "  * The previous code cell split the original training set into:\n",
        "    * a reduced training set (the original training set - the validation set)\n",
        "    * the validation set \n",
        "  * By default, the pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method outputs the *first* 5 rows of the DataFrame. To see more of the training set, specify the `n` argument to `head` and assign a large positive integer to `n`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJQcAZkwJt_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "c22a8ea7-9651-4728-96b6-460945b3e3e0"
      },
      "source": [
        "# Write some code in this code cell.\n",
        "train_df.head(30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-115.3</td>\n",
              "      <td>32.8</td>\n",
              "      <td>34.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1602.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>71.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1276.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>867.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>80.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>623.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>68.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>-115.4</td>\n",
              "      <td>32.8</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1458.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>74.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    longitude  latitude  ...  median_income  median_house_value\n",
              "0      -114.3      34.2  ...            1.5                66.9\n",
              "1      -114.5      34.4  ...            1.8                80.1\n",
              "2      -114.6      33.7  ...            1.7                85.7\n",
              "3      -114.6      33.6  ...            3.2                73.4\n",
              "4      -114.6      33.6  ...            1.9                65.5\n",
              "..        ...       ...  ...            ...                 ...\n",
              "25     -115.3      32.8  ...            3.7               100.0\n",
              "26     -115.4      32.8  ...            3.6                71.1\n",
              "27     -115.4      32.8  ...            1.9                80.9\n",
              "28     -115.4      32.8  ...            1.8                68.6\n",
              "29     -115.4      32.8  ...            2.4                74.3\n",
              "\n",
              "[30 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnNvkFwwK8WY",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "301f0da8-9b3c-4ff9-e2c7-e89b5ec4c919"
      },
      "source": [
        "#@title Double-click for a possible solution to Task 2.\n",
        "\n",
        "# Examine examples 0 through 4 and examples 25 through 29\n",
        "# of the training set\n",
        "train_df.head(n=1000)\n",
        "\n",
        "# The original training set is sorted by longitude. \n",
        "# Apparently, longitude influences the relationship of\n",
        "# total_rooms to median_house_value."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.2</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     longitude  latitude  ...  median_income  median_house_value\n",
              "0       -114.3      34.2  ...            1.5                66.9\n",
              "1       -114.5      34.4  ...            1.8                80.1\n",
              "2       -114.6      33.7  ...            1.7                85.7\n",
              "3       -114.6      33.6  ...            3.2                73.4\n",
              "4       -114.6      33.6  ...            1.9                65.5\n",
              "..         ...       ...  ...            ...                 ...\n",
              "995     -117.1      32.5  ...            4.0               144.4\n",
              "996     -117.1      34.6  ...            3.2               112.8\n",
              "997     -117.1      34.2  ...            4.5               108.4\n",
              "998     -117.1      34.0  ...            2.5                96.0\n",
              "999     -117.1      33.6  ...            4.4               307.6\n",
              "\n",
              "[1000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw4xI1ZEckI8",
        "colab_type": "text"
      },
      "source": [
        "## Task 3. Fix the problem\n",
        "\n",
        "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and validation set. To do so, take the following steps:\n",
        "\n",
        "1. Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (in the code cell associated with Task 1):\n",
        "\n",
        "```\n",
        "  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
        "```                                    \n",
        "\n",
        "2. Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (in the code call associated with Task 1) so that the call becomes as follows:\n",
        "\n",
        "```\n",
        "  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                      my_label, epochs, batch_size, \n",
        "                                      validation_split)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncODhpv0h-LG",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f49b3a5b-b5dc-4f18-9a0c-94529f55a9c2"
      },
      "source": [
        "#@title Double-click to view the complete implementation.\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.7\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Shuffle the examples.\n",
        "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n",
        "\n",
        "# Invoke the functions to build and train the model. Train on the shuffled\n",
        "# training set.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 50631.1758 - root_mean_squared_error: 225.0137 - val_loss: 45473.3086 - val_root_mean_squared_error: 213.2447\n",
            "Epoch 2/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 41946.2148 - root_mean_squared_error: 204.8078 - val_loss: 37706.5430 - val_root_mean_squared_error: 194.1817\n",
            "Epoch 3/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 34481.7930 - root_mean_squared_error: 185.6927 - val_loss: 30854.9961 - val_root_mean_squared_error: 175.6559\n",
            "Epoch 4/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 27952.4258 - root_mean_squared_error: 167.1898 - val_loss: 24969.0488 - val_root_mean_squared_error: 158.0160\n",
            "Epoch 5/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 22308.9297 - root_mean_squared_error: 149.3617 - val_loss: 19879.3633 - val_root_mean_squared_error: 140.9942\n",
            "Epoch 6/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 17637.9980 - root_mean_squared_error: 132.8081 - val_loss: 15724.4043 - val_root_mean_squared_error: 125.3970\n",
            "Epoch 7/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 13765.9795 - root_mean_squared_error: 117.3285 - val_loss: 12346.3447 - val_root_mean_squared_error: 111.1141\n",
            "Epoch 8/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 10837.8682 - root_mean_squared_error: 104.1051 - val_loss: 9869.1709 - val_root_mean_squared_error: 99.3437\n",
            "Epoch 9/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 8780.7471 - root_mean_squared_error: 93.7056 - val_loss: 8214.2402 - val_root_mean_squared_error: 90.6324\n",
            "Epoch 10/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 7493.8037 - root_mean_squared_error: 86.5668 - val_loss: 7316.5649 - val_root_mean_squared_error: 85.5369\n",
            "Epoch 11/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7011.3027 - root_mean_squared_error: 83.7335 - val_loss: 7069.7505 - val_root_mean_squared_error: 84.0818\n",
            "Epoch 12/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6933.5151 - root_mean_squared_error: 83.2677 - val_loss: 7052.8613 - val_root_mean_squared_error: 83.9813\n",
            "Epoch 13/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6930.5249 - root_mean_squared_error: 83.2498 - val_loss: 7050.6670 - val_root_mean_squared_error: 83.9682\n",
            "Epoch 14/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.7163 - root_mean_squared_error: 83.2449 - val_loss: 7050.8296 - val_root_mean_squared_error: 83.9692\n",
            "Epoch 15/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6931.5898 - root_mean_squared_error: 83.2562 - val_loss: 7050.9014 - val_root_mean_squared_error: 83.9696\n",
            "Epoch 16/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6930.7334 - root_mean_squared_error: 83.2510 - val_loss: 7053.5161 - val_root_mean_squared_error: 83.9852\n",
            "Epoch 17/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6930.5820 - root_mean_squared_error: 83.2501 - val_loss: 7054.0698 - val_root_mean_squared_error: 83.9885\n",
            "Epoch 18/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.9600 - root_mean_squared_error: 83.2464 - val_loss: 7053.7412 - val_root_mean_squared_error: 83.9866\n",
            "Epoch 19/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.6660 - root_mean_squared_error: 83.2386 - val_loss: 7049.8506 - val_root_mean_squared_error: 83.9634\n",
            "Epoch 20/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6930.0889 - root_mean_squared_error: 83.2472 - val_loss: 7050.7480 - val_root_mean_squared_error: 83.9687\n",
            "Epoch 21/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.4126 - root_mean_squared_error: 83.2431 - val_loss: 7051.1367 - val_root_mean_squared_error: 83.9710\n",
            "Epoch 22/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.5371 - root_mean_squared_error: 83.2318 - val_loss: 7049.2744 - val_root_mean_squared_error: 83.9600\n",
            "Epoch 23/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.6147 - root_mean_squared_error: 83.2383 - val_loss: 7048.7026 - val_root_mean_squared_error: 83.9566\n",
            "Epoch 24/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6930.1943 - root_mean_squared_error: 83.2478 - val_loss: 7051.5527 - val_root_mean_squared_error: 83.9735\n",
            "Epoch 25/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.7153 - root_mean_squared_error: 83.2389 - val_loss: 7050.7480 - val_root_mean_squared_error: 83.9687\n",
            "Epoch 26/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.4932 - root_mean_squared_error: 83.2436 - val_loss: 7054.1851 - val_root_mean_squared_error: 83.9892\n",
            "Epoch 27/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.5679 - root_mean_squared_error: 83.2320 - val_loss: 7049.9043 - val_root_mean_squared_error: 83.9637\n",
            "Epoch 28/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.0454 - root_mean_squared_error: 83.2409 - val_loss: 7050.7158 - val_root_mean_squared_error: 83.9685\n",
            "Epoch 29/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.6206 - root_mean_squared_error: 83.2383 - val_loss: 7051.9072 - val_root_mean_squared_error: 83.9756\n",
            "Epoch 30/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6925.9287 - root_mean_squared_error: 83.2222 - val_loss: 7061.4473 - val_root_mean_squared_error: 84.0324\n",
            "Epoch 31/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.9570 - root_mean_squared_error: 83.2404 - val_loss: 7053.2773 - val_root_mean_squared_error: 83.9838\n",
            "Epoch 32/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.1226 - root_mean_squared_error: 83.2353 - val_loss: 7052.2085 - val_root_mean_squared_error: 83.9774\n",
            "Epoch 33/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.7583 - root_mean_squared_error: 83.2392 - val_loss: 7051.6270 - val_root_mean_squared_error: 83.9740\n",
            "Epoch 34/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.9922 - root_mean_squared_error: 83.2406 - val_loss: 7053.3535 - val_root_mean_squared_error: 83.9842\n",
            "Epoch 35/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.1372 - root_mean_squared_error: 83.2414 - val_loss: 7056.0513 - val_root_mean_squared_error: 84.0003\n",
            "Epoch 36/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.1113 - root_mean_squared_error: 83.2353 - val_loss: 7051.0400 - val_root_mean_squared_error: 83.9705\n",
            "Epoch 37/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.0391 - root_mean_squared_error: 83.2409 - val_loss: 7054.5049 - val_root_mean_squared_error: 83.9911\n",
            "Epoch 38/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.6367 - root_mean_squared_error: 83.2324 - val_loss: 7049.8105 - val_root_mean_squared_error: 83.9632\n",
            "Epoch 39/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.9019 - root_mean_squared_error: 83.2340 - val_loss: 7051.6338 - val_root_mean_squared_error: 83.9740\n",
            "Epoch 40/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.9160 - root_mean_squared_error: 83.2401 - val_loss: 7053.4482 - val_root_mean_squared_error: 83.9848\n",
            "Epoch 41/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.0947 - root_mean_squared_error: 83.2352 - val_loss: 7051.9863 - val_root_mean_squared_error: 83.9761\n",
            "Epoch 42/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.6509 - root_mean_squared_error: 83.2385 - val_loss: 7053.0366 - val_root_mean_squared_error: 83.9824\n",
            "Epoch 43/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.9097 - root_mean_squared_error: 83.2341 - val_loss: 7051.3369 - val_root_mean_squared_error: 83.9722\n",
            "Epoch 44/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6926.1245 - root_mean_squared_error: 83.2233 - val_loss: 7049.5864 - val_root_mean_squared_error: 83.9618\n",
            "Epoch 45/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6925.9795 - root_mean_squared_error: 83.2225 - val_loss: 7059.4004 - val_root_mean_squared_error: 84.0202\n",
            "Epoch 46/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6926.3247 - root_mean_squared_error: 83.2245 - val_loss: 7050.7354 - val_root_mean_squared_error: 83.9687\n",
            "Epoch 47/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.9326 - root_mean_squared_error: 83.2402 - val_loss: 7055.5991 - val_root_mean_squared_error: 83.9976\n",
            "Epoch 48/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.0503 - root_mean_squared_error: 83.2349 - val_loss: 7052.9668 - val_root_mean_squared_error: 83.9819\n",
            "Epoch 49/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.2095 - root_mean_squared_error: 83.2359 - val_loss: 7055.6772 - val_root_mean_squared_error: 83.9981\n",
            "Epoch 50/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.7441 - root_mean_squared_error: 83.2391 - val_loss: 7054.2280 - val_root_mean_squared_error: 83.9894\n",
            "Epoch 51/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6925.9858 - root_mean_squared_error: 83.2225 - val_loss: 7050.3706 - val_root_mean_squared_error: 83.9665\n",
            "Epoch 52/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6927.6133 - root_mean_squared_error: 83.2323 - val_loss: 7052.2251 - val_root_mean_squared_error: 83.9775\n",
            "Epoch 53/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.6147 - root_mean_squared_error: 83.2383 - val_loss: 7052.2939 - val_root_mean_squared_error: 83.9779\n",
            "Epoch 54/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6927.7583 - root_mean_squared_error: 83.2332 - val_loss: 7051.6167 - val_root_mean_squared_error: 83.9739\n",
            "Epoch 55/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.0879 - root_mean_squared_error: 83.2351 - val_loss: 7050.8203 - val_root_mean_squared_error: 83.9692\n",
            "Epoch 56/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.3403 - root_mean_squared_error: 83.2367 - val_loss: 7053.6685 - val_root_mean_squared_error: 83.9861\n",
            "Epoch 57/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6926.2896 - root_mean_squared_error: 83.2243 - val_loss: 7060.8740 - val_root_mean_squared_error: 84.0290\n",
            "Epoch 58/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.0127 - root_mean_squared_error: 83.2407 - val_loss: 7053.8184 - val_root_mean_squared_error: 83.9870\n",
            "Epoch 59/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.9458 - root_mean_squared_error: 83.2403 - val_loss: 7053.3833 - val_root_mean_squared_error: 83.9844\n",
            "Epoch 60/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.8579 - root_mean_squared_error: 83.2398 - val_loss: 7054.2656 - val_root_mean_squared_error: 83.9897\n",
            "Epoch 61/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.9233 - root_mean_squared_error: 83.2341 - val_loss: 7054.8062 - val_root_mean_squared_error: 83.9929\n",
            "Epoch 62/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.0864 - root_mean_squared_error: 83.2411 - val_loss: 7052.5547 - val_root_mean_squared_error: 83.9795\n",
            "Epoch 63/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.7363 - root_mean_squared_error: 83.2390 - val_loss: 7055.8022 - val_root_mean_squared_error: 83.9988\n",
            "Epoch 64/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6926.2407 - root_mean_squared_error: 83.2240 - val_loss: 7050.0869 - val_root_mean_squared_error: 83.9648\n",
            "Epoch 65/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.2070 - root_mean_squared_error: 83.2298 - val_loss: 7052.2314 - val_root_mean_squared_error: 83.9776\n",
            "Epoch 66/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.7202 - root_mean_squared_error: 83.2389 - val_loss: 7051.9897 - val_root_mean_squared_error: 83.9761\n",
            "Epoch 67/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6928.4243 - root_mean_squared_error: 83.2372 - val_loss: 7053.4678 - val_root_mean_squared_error: 83.9849\n",
            "Epoch 68/70\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 6928.6108 - root_mean_squared_error: 83.2383 - val_loss: 7051.9346 - val_root_mean_squared_error: 83.9758\n",
            "Epoch 69/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6927.5835 - root_mean_squared_error: 83.2321 - val_loss: 7050.2129 - val_root_mean_squared_error: 83.9655\n",
            "Epoch 70/70\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6929.0908 - root_mean_squared_error: 83.2412 - val_loss: 7055.4917 - val_root_mean_squared_error: 83.9970\n",
            "121.58558654785156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKN239_miW8C",
        "colab_type": "text"
      },
      "source": [
        "Experiment with `validation_split` to answer the following questions:\n",
        "\n",
        "* With the training set shuffled, is the final loss for the training set closer to the final loss for the validation set?  \n",
        "* At what range of values of `validation_split` do the final loss values for the training set and validation set diverge meaningfully?  Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UAJ3Q86iz31",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Double-click for the answers to the questions\n",
        "\n",
        "# Yes, after shuffling the original training set, \n",
        "# the final loss for the training set and the \n",
        "# validation set become much closer.\n",
        "\n",
        "# If validation_split < 0.15,\n",
        "# the final loss values for the training set and\n",
        "# validation set diverge meaningfully.  Apparently,\n",
        "# the validation set no longer contains enough examples. "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PP-O8TOZOeo",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n",
        "\n",
        "The test set usually acts as the ultimate judge of a model's quality. The test set can serve as an impartial judge because its examples haven't been used in training the model. Run the following code cell to evaluate the model with the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd_Sw2cygOip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42b2dce2-b597-47f0-e8cf-74315fa06b23"
      },
      "source": [
        "x_test = test_df[my_feature]\n",
        "y_test = test_df[my_label]\n",
        "\n",
        "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 931us/step - loss: 7012.5332 - root_mean_squared_error: 83.7409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoyQKvsjmV_A",
        "colab_type": "text"
      },
      "source": [
        "Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
        "\n",
        "* training set: look for `root_mean_squared_error` in the final training epoch.\n",
        "* validation set: look for `val_root_mean_squared_error` in the final training epoch.\n",
        "* test set: run the preceding code cell and examine the `root_mean_squred_error`.\n",
        "\n",
        "Ideally, the root mean squared error of all three sets should be similar. Are they?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXtp-aVdIgJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Double-click for an answer\n",
        "\n",
        "# In our experiments, yes, the rmse values \n",
        "# were similar enough. "
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}